# 训练误差和泛化误差
- **训练误差 (Training Error)**：模型在**训练数据集**上算出来的误差。这就像你平时做练习册的正确率。
    
- **泛化误差 (Generalization Error)**：模型应用在从原始样本分布中抽取的**无限多**数据样本时，误差的**期望**。这就像你参加真正高考时的预期表现。
    
    - _注意_：我们永远无法算出一个确切的“泛化误差”，因为我们拿不到“无限多”的数据。我们只能用**测试集**的误差来**估计**它。

# 统计学习理论

**独立同分布假设 (i.i.d. assumption)**：我们假设训练数据和测试数据是从**相同的分布**中**独立**提取的。

- **解释**：比如我们用“大学生的人脸”训练模型，去检测“养老院的老人”，这就违反了**同分布**（分布不同），模型肯定失效。比如预测微博热搜，今天的新闻和昨天强相关，这就违反了**独立性**。
    
- **为什么这样做？** 只有假设过去的数据和未来的数据遵循同样的规律，我们从过去学到的经验才能应用到未来。

# 模型复杂性
模型太简单学不会（欠拟合），模型太复杂容易钻牛角尖（过拟合）。这取决于：

1. **参数数量**：参数越多，自由度越高，越容易过拟合。
2. **参数取值范围**：权重的取值范围越大，模型越灵活，越容易过拟合。
3. **训练样本数**：样本太少，简单的模型也会过拟合（比如只有2个点，一条直线就能完美穿过，但这未必是真实规律）。

# 模型选择

## 验证集

**验证集** 我们把数据分成三份：

1. **训练集 (Training Set)**：用来计算梯度，更新参数（平时作业）。
2. **验证集 (Validation Set)**：用来评估不同超参数的效果，选择最佳模型（模拟考试）。
3. **测试集 (Test Set)**：只在模型最终确定后跑一次，作为最终结果汇报（最终高考）。
- _注_：课件中特别提到，我们在书里的实验，因为数据有限，通常拿到的所谓“测试集”其实充当的是“验证集”的角色。

## K折交叉验证

- **场景**：数据少得可怜，切出一块验证集后，训练集就不够用了。
    
- **做法**：
    1. 把原始训练数据切分成 $K$ 个不重叠的子集（比如 $K=5$）。
    2. 进行 $K$ 轮训练。每一轮，选其中 1 个子集当验证集，剩下 $K-1$ 个当训练集。
    3. 最后，把这 $K$ 次实验的**验证误差取平均值**，作为该模型的衡量标准。
- **为什么这样做？** 这样每个样本都既当过训练数据，又当过验证数据，评估结果更稳定，不浪费数据
# 欠拟合还是过拟合？

- **欠拟合 (Underfitting)**：
    - **表现**：训练误差和验证误差**都很高**，且两者差距很小。
    - **原因**：模型太简单（模型容量低），连现有的样本规律都学不会。
    - **例子**：用一条直线去拟合一个抛物线数据，怎么摆都拟合不好。
- **过拟合 (Overfitting)**
    - **表现**：训练误差**很低**，但验证误差**很高**。两者之间有一个**巨大的缺口 (Gap)**。
    - **原因**：模型太复杂（模型容量高），学到了很多只在训练集中存在的噪声，没学到普遍规律。
    - **例子**：用一个高阶多项式强行穿过所有数据点，曲线扭曲得很厉害，稍微给个新数据就预测偏了。
## 模型复杂性

- **模型复杂性**：
    - 简单模型（参数少）：容易欠拟合。
    - 复杂模型（参数多、取值范围大）：容易过拟合。
    - **目标**：找到中间的平衡点（泛化误差最小的点）。
- **数据集大小**：
    - 数据越少，越容易过拟合（哪怕模型很简单，只有两个样本也能轻易被记住）。
    - 数据越多，越能容忍复杂的模型，泛化误差通常会降低。
    - _金句_：深度学习的成功很大程度上归功于海量数据。
![[Pasted image 20251127232326.png]]

# 多项式回归

我们定义一个单特征的输入 $x$，并用一个 $d$ 阶多项式来生成标签 $y$。

$$\hat{y} = \sum_{i=0}^d x^i w_i$$

这其实就是一个标准的线性回归问题，只不过我们把 $x, x^2, x^3, ...$ 看作是不同的特征。
真实规律：
$$y = 5 + 1.2x - 3.4\frac{x^2}{2!} + 5.6\frac{x^3}{3!} + \epsilon$$

这里有两点需要特别解释：
1. **真实权重**：$w = [5, 1.2, -3.4, 5.6]$。前四项对应的分别是 $x^0, x^1, x^2, x^3$ 的系数。
2. **为什么要除以 $i!$（阶乘）？**
    - **通俗解释**：如果 $x=2$，那么 $x^{20}$ 是一个天文数字（一百万左右）。这样的数字输入进去，权重稍微有一点变化，输出就会剧烈波动，导致梯度爆炸，模型根本训练不起来。除以阶乘 $i!$ 可以把高阶项的数值拉回到一个正常的范围（类似归一化）。
# **三组实验结果分析**
- **实验一：正常拟合（三阶多项式）**
    - **设置**：我们用**前4列**特征（$x^0$ 到 $x^3$）来训练。这与生成数据的真实阶数完全一致。
    - **结果**：
        - 训练损失和测试损失**都降得很低**。
        - 学习到的权重非常接近真实权重 `[5, 1.2, -3.4, 5.6]`。
    - **结论**：模型复杂度匹配，效果最佳。
- **实验二：欠拟合（线性函数拟合）**
    - **设置**：我们只用**前2列**特征（$x^0$ 和 $x^1$），也就是试图用一条直线去拟合一个弯曲的三次曲线。
    - **结果**
        - 训练损失和测试损失**都很高**，而且怎么训练都降不下去。
    - **结论**：模型太简单，表达能力不足（Underfitting）。
- **实验三：过拟合（高阶多项式拟合）**
    - **设置**：我们使用了**所有20列**特征（最高到 $x^{19}$），试图用一个极为复杂的曲线去拟合这100个点。
    - **结果**：
        - 训练损失**非常低**（甚至接近0）。
        - 测试损失**非常高**，且保持不变甚至上升。
        - 两条曲线之间的**缺口（Gap）巨大**。
        - 学习到的权重通常会变得非常大且杂乱（为了强行穿过每一个噪声点）。
    - **结论**：模型太复杂，死记硬背了训练集中的噪声（Overfitting）。