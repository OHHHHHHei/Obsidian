# 读取数据集

```python
# 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，
# 并除以255使得所有像素的数值均在0～1之间
trans = transforms.ToTensor()
```

这里定义了一个变换操作 trans。
**原始数据：** 图像通常是以 PIL Image 对象或 `uint8` 类型的 NumPy 数组存储的，像素值范围是 $[0, 255]$（0是黑，255是白）。

为什么要除以 255？

神经网络喜欢数值比较小的输入，通常在 $[0, 1]$ 或 $[-1, 1]$ 之间。$$\text{Normalized Pixel} = \frac{\text{Original Pixel}}{255.0}$$
这样可以加速梯度下降的收敛。transforms.ToTensor() 会自动帮我们完成这个“除以255”和“转为浮点数”的操作，并将通道顺序调整为 PyTorch 需要的格式。

# 数据集规模与维度

“Fashion-MNIST由10个类别的图像组成... 训练集60000张，测试集10000张... 每个输入图像的高度和宽度均为28像素... 通道数为1。”

- **类别数 (Classes) = 10**：这意味着输出层通常需要有 10 个神经元（对应 Softmax 的 10 个概率输出）。
- **样本量**：
    - 训练集：60,000。数据量越大，越不容易过拟合。
    - 测试集：10,000。
- 图像尺寸与符号表示：
    文档中提到：高度 $h$ 像素，宽度 $w$ 像素，记为 $h \times w$。
    在这里，$h = 28, w = 28$。
    如果是灰度图，通道数 $c=1$。

# 类别标签与可视化

定义了 `get_fashion_mnist_labels` 函数和 `show_images` 函数。

- **标签转换**：计算机只认识数字（0, 1, ... 9），但人类需要看文字（T-shirt, Dress）。`get_fashion_mnist_labels` 就是做一个简单的映射，把索引映射到具体的衣服名称。
- **可视化**：`show_images` 函数利用 `matplotlib` 画图。这在工程中很有用，我们需要时不时把图片打印出来，看看数据有没有读错，或者预处理（如旋转、裁剪）是否符合预期。

# 读取小批量

## 定义数据加载器

```python
batch_size = 256

def get_dataloader_workers():  #@save
    """使用4个进程来读取数据"""
    return 4

train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True,
                             num_workers=get_dataloader_workers())
```
- **`batch_size = 256`**：
    - **含义**：每次训练迭代，我们给模型喂 256 张图片。
    - **为什么是256？** 这是一个超参数。
        - 太小（如1）：计算不稳定，且无法充分利用 GPU 的并行计算能力。
        - 太大（如60000）：内存/显存塞不下。
        - 256 是一个经验值，通常是 2 的幂次方（32, 64, 128, 256...）。
- **`get_dataloader_workers()`**：
    - 这是一个简单的封装函数，返回 `4`。
    - **含义**：告诉 PyTorch 同时开 4 个子进程（Process）来预读取数据。
    - **原理**：当 GPU 正在计算第 1 批数据时，CPU 的这 4 个进程已经在拼命读取和处理第 2、3、4 批数据了。这样 GPU 算完后，下一批数据已经准备好了，不用停下来等。
- **`data.DataLoader(...)`**：
    - `dataset=mnist_train`：指定搬运哪个仓库的货物。
    - `batch_size`：指定每次搬多少。
    - `shuffle=True`：**非常重要！** 表示“洗牌”。
        - 在每个 Epoch（所有数据训练一轮）开始时，重新打乱数据顺序。
        - **注意**：训练集通常设为 `True`，测试集通常设为 `False`（因为测试不需要随机，只要测完就行）。
    - `num_workers`：搬运工的数量。

