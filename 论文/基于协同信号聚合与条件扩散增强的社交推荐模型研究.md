# 信息过滤技术

主动式根据关键词实现定向信息获取

被动式的推荐系统

# 贝叶斯个性化排序

问题：如何从只有正反馈（点击、购买、播放）的数据中，学习用户的偏好顺序？

BPR做了一个非常符合直觉的假设：

**对于同一个用户，他播放过的歌曲（正样本），应该比他没播放过的歌曲（负样本）更受偏爱** 。
- **正样本 (Positive Item):** 你播放过的歌曲，比如周杰伦的《晴天》。
- **负样本 (Negative Item):** 数据库里成千上万首你还没播放过的歌曲，比如随机挑一首你没听过的网络歌曲。
BPR认为，既然你选择了播放《晴天》，而没有选择那首网络歌曲，那么在你的个人排行榜里，《晴天》的排名就应该**高于**那首网络歌曲。

PR的学习过程就像是不断地进行“配对比较”练习，来让推荐系统变得更懂你。

- **构建训练三元组：** 系统会为你构建大量的训练数据，每个数据都是一个三元组 `(你, 《晴天》, 某首未听过的歌)`，这个组合的含义是“你更偏爱《晴天》，胜过那首未听过的歌” 。
- **打分与调整：** 推荐系统内部会为用户和歌曲都学习一个“特征向量”（可以理解为一组描述性格或风格的数字）。通过计算你和一首歌的特征向量的内积（可以想象成计算匹配度），得出一个偏好分数 $\hat{r}$ 。
- **优化目标：** BPR的目标就是，在每一次“配对比较”中，都**尽可能让正样本的得分高于负样本的得分** 。它希望
    $\hat{r}_{你,《晴天》}$  与 $\hat{r}_{你, 某未听过的歌​}$ 的分差越大越好。

所以，贝叶斯个性化排序（BPR）的本质就是：

**它不关心一首歌的具体评分是多少，只关心歌曲之间的相对排序。通过构建大量的“A比B好”这样的偏好对，直接针对“排序”这个目标进行优化，非常适合为用户生成Top-N推荐列表的任务。**

# 深度协同过滤模型

使用图神经网络GNN，能更有效利用其他用户与物品的关系

# 生成式推荐模型

生成对抗网络

变分子编码器

扩散概率

# 社交推荐模型

# 协同过滤技术

## 基于记忆的协同过滤

### 基于用户的协同过滤

假设相似用户对物品的兴趣是趋同的

计算预测评分的公式如下

$$\hat{r}_{u,i} = \underbrace{\bar{r}_u}_{\text{Part 1: 个人基准分}} + \underbrace{\frac{\sum_{v \in N_u} sim(u,v) \cdot (r_{v,i} - r_v)}{\sum_{v \in N_u} |sim(u,v)|}}_{\text{Part 2: 综合他人意见后的调整值}}$$

它的核心逻辑可以类比为：**“要预测你会不会喜欢一部你没看过的电影，可以先看看你的‘品味搭子’们（和你口味相似的人）是怎么评价这部电影的，再结合你自己的打分习惯，给出一个预测。”** 
### 基于物品的协同过滤

假设用户对相似物品的兴趣一致，也通过类似公式预测目标用户对相应物品的偏好

## 基于模型的协同过滤

### 矩阵分解模型 

想象一下，我们有一个巨大的表格，记录了所有用户对所有物品的评分，但这个表格非常空，因为每个用户只与一小部分物品互动过。矩阵分解的核心任务就是**预测并填补这些空格** 。
它的核心思想非常巧妙：**它假设每个用户和每个物品都可以用一组共同的“潜在因子”来描述** 。
我们可以把这个过程比作是分析美食口味：
- **原始数据：** 用户A喜欢火锅，用户B喜欢麻辣香锅，用户C喜欢毛血旺。
- **潜在因子：** 我们可以提炼出一些“口味因子”，比如`{麻度, 辣度, 油腻度, ...}`。
- **用户因子矩阵 (P)：** 描述每个用户对这些口味因子的偏好程度。
    - 用户A：`{麻度: 8, 辣度: 7, 油腻度: 6}`
    - 用户B：`{麻度: 9, 辣度: 8, 油腻度: 5}`
- **物品因子矩阵 (Q)：** 描述每道菜含有这些口味因子的程度。
    - 火锅：`{麻度: 7, 辣度: 7, 油腻度: 8}`
    - 毛血旺：`{麻度: 8, 辣度: 9, 油腻度: 9}
矩阵分解做的就是**将原始的、巨大的“用户-物品”评分矩阵，拆解成这两个更小的“用户-因子”和“物品-因子”矩阵** 。

具体来说，评分矩阵就是巨大，稀疏的交互矩阵。用户隐向量矩阵就是用户对不同因子的偏好，物品隐向量矩阵就是物品含有这些因子的具体量化。

**预测评分**的过程，就是将一个用户的因子向量和一个物品的因子向量做**内积**运算 。

$$\hat{r}_{u,i} = \mathbf{p}_u^T \cdot \mathbf{q}_i$$ 
**直观理解**：如果用户A的“口味向量”和毛血旺的“口味向量”非常匹配（对应维度上的数值都很高），那么它们的内积结果就会很高。模型就会据此预测用户A很可能会喜欢毛血旺。

接着再通过特定任务的目标函数,如最小化评分预测误差,来学习参数

$$\min_{P,Q} \underbrace{\sum_{(u,i) \in \mathcal{K}} \left( r_{u,i} - \mathbf{p}_u^T \mathbf{q}_i \right)^2}_{\text{Part 1: 预测误差}} + \lambda \underbrace{\left( \|\mathbf{P}\|_F^2 + \|\mathbf{Q}\|_F^2 \right)}_{\text{Part 2: 正则化项}}$$ 
第一部分就是计算模型在所有已知评分上的“总预测误差”，我们当然希望这个总误差越小越好。
第二部分是为了**防止模型变得过于复杂，避免“过拟合” (Overfitting)** 。
- **什么是过拟合？** 想象一个学生，他把练习册上的所有题目和答案都死记硬背下来了，所以练习册测验能考100分。但一到正式考试，遇到新题型就完全不会了。这就是过拟合：模型对训练数据（已知的评分）拟合得太完美，但失去了对未知数据（没评过分的物品）的预测能力。简单来说就是失去了预测能力。

- **$||P||_F^2 + ||Q||_F^2$**:     这部分计算了 P 和 Q 两个矩阵中所有元素的平方和。你可以把它理解为对模型**复杂度**的一种度量。如果模型为了完美拟合已知评分，而学到了非常大或非常极端的潜在因子数值，那么这个复杂度度量就会变得很大。

- **$\lambda$**: 这是一个**正则化系数** ，像一个“旋钮”。由我们手动设置，用来控制我们对模型复杂度的“惩罚”力度。
    - $\lambda$ 越大，模型就越倾向于学习更小、更平滑的因子值，模型会更“简单”，但也可能导致对已知评分的拟合不够好。
    - $\lambda$ 越小，模型就越专注于减小预测误差，但有过拟合的风险。

### 神经协同过滤

把线性化的内积操作改为神经网络的深度学习预测操作

# 排序学习技术

## Point-wise 方法

将排序任务简化为单个物品的评分预测

## Pair-wise 方法

以物品对(Item Pair)为训练单元,最大化正样本物品(如已购买商品)相对于负样本的排序得分差异,学习用户的偏好序关系。

以完整物品列表为优化对象,通过建模列表中物品的  全局依赖关系,直接学习与用户真实偏好匹配的排序分布。

我们以贝叶斯个性化排序（BPR）为例子

$$P(i >_u j | \Theta) = \sigma(\hat{r}_{u,i} - \hat{r}_{u,j}) \,。$$ 
代表在给定模型参数 $\Theta$ 的情况下，模型预测“用户 u 对物品 i 的偏好 **大于** 对物品 j 的偏好”这件事的**概率** 

$\sigma(\cdot)$  ：这是 **Sigmoid函数**，它的作用是把任意一个数值（比如上面那个分数差）压缩到0和1之间，变成一个概率值 。如果分数差很大，这个概率就趋近于1；如果分数差是负数，概率就趋近于0。

最终的损失函数

$$\mathcal{L}_{BPR} = \sum_{(u,i,j) \in \mathcal{D}} -\ln \sigma(\hat{r}_{u,i} - \hat{r}_{u,j}) + \lambda \|\Theta\|^2,$$ 
**$-ln \sigma(\hat{r}_{u,i} - \hat{r}_{u,j})$  这是核心的损失部分。它的目标是最大化上面公式中的概率。在数学上，最大化一个概率值等价于最小化这个概率的负对数。当模型预测正确（概率趋近1）时，这个损失项会趋近于0；当模型预测错误（概率趋近0）时，这个损失会变得非常大，从而“惩罚”模型，促使它调整参数。

## List-wise 方法

直接着眼于整个推荐列表的最终排列，最终目标是让模型预测出的排序分布（预测排序分布）尽可能地去接近用户心中真正的排序分布（理想排序分布）

以ListNet为例

下面这个公式计算的是这个公式计算的是，在给定模型对所有物品的预测分数 $\hat{r}$ 的情况下，某个**特定的排序 $\pi$** (比如 `物品A > 物品C > 物品B`) 出现的**概率**是多少 。
$$P(\pi|\hat{\mathbf{r}}) = \prod_{k=1}^{n} \frac{\Phi(\hat{r}_{i_k})}{\sum_{m=k}^{n} \Phi(\hat{r}_{i_m})},$$ 
具体意义如下

第一步：选出排名第1的物品 (k=1)
**计算**：$$\frac{\Phi(\hat{r}_A)}{\Phi(\hat{r}_A) + \Phi(\hat{r}_B) + \Phi(\hat{r}_C)}$$ 

- $\Phi(\cdot)$  是一个转换函数（通常是指数函数 $e^x$ ），用来把分数变成正数并拉开差距 。

第二步：选出排名第2的物品 (k=2)

$$\frac{\Phi(\hat{r}_B)}{\Phi(\hat{r}_B) + \Phi(\hat{r}_C)}$$  
第三步：选出排名第3的物品 (k=3)

$$\frac{\Phi(\hat{r}_C)}{\Phi(\hat{r}_C)} = 1$$ 
最后：将每一步的概率相乘
$$P("A>B>C" | \hat{r}) = \left( \frac{\Phi(\hat{r}_A)}{\Phi(\hat{r}_A) + \Phi(\hat{r}_B) + \Phi(\hat{r}_C)} \right) \times \left( \frac{\Phi(\hat{r}_B)}{\Phi(\hat{r}_B) + \Phi(\hat{r}_C)} \right) \times \left( \frac{\Phi(\hat{r}_C)}{\Phi(\hat{r}_C)} \right)$$  

由以上可知：完整比较所有排列比较困难，我们可以直接比A,B,C分别排在第一名的概率是多少
$$P(i|\hat{r})=\frac{\Phi(\hat{r}_{i})}{\sum_{j=1}^{n}\Phi(\hat{r}_{j})}$$  
通过这个简化，ListNet成功地将一个复杂的“排列”问题，转换成了一个更简单的“概率分布”问题 。

现在我们有了每个物品排在第一名的预测分布，我们可以从用户真实数据中得到真实分布

接着我们计算**交叉熵 (Cross-entropy)** ，这是一种在机器学习中专门用来衡量两个概率分布之间**差异**的工具。
- 如果两个分布非常接近，交叉熵损失就**很小**。
- 如果两个分布差异很大，交叉熵损失就**很大**。
计算公式如下
$$\mathcal{L}_{ListNet} = -\sum_{\pi \in \Pi} \sum_{i=1}^{n} P_{true}(i) \log P_{pred}(i)$$ 
模型通过不断调整参数，来**最小化这个交叉熵损失**，也就是驱动“预测分布”去无限逼近“真实分布”。

# 基于图神经网络的推荐模型

## 图卷积网络建模

图卷积网络将传统卷积推广到图结构数据

- **图像卷积**：一个像素点的值，由它周围像素点的值加权决定。
    
- **图卷积**：一个节点（用户或物品）的特征，由它**邻居节点**（与之有连接的物品或用户）的特征加权决定。

它能显式地捕捉到**协同信号 (Collaborative Signal)**，即“物以类聚，人以群分”的思想，从而缓解数据稀疏问题 。

卷积可以提取特征。对用户而言，用户的第一层卷积对象是物品，我们可以提取到跟这个用户交互过的物品的特征，第二层卷积是和那些物品交互过的对象，跟这些用户卷积我们可以提取到跟这个用户具有相似品味的用户的特征，接着依次往下卷积。对物品而言同理。

### NGCF神经图协同过滤

**第一步：嵌入初始化**

- 为每个用户u和物品i分配一个初始的低维特征向量 $e_u^{(0)}$ ​ 和 $e_i^{(0)}$ ​ 。这可以看作是它们的“初始画像”。

**第二步：多层信息传播 (核心)**

- 通过堆叠L层GCN操作，让信息在图上传播。一个用户节点会聚合它直接连接的物品节点的信息，一个物品节点也会聚合喜欢它的用户节点的信息。
- 传播L层，就意味着每个节点都融合了其**L跳邻居**的信息，从而捕捉到高阶的关联性 。

**信息传播公式 (Message Propagation)**:
$$\mathbf{m}_{u \leftarrow i}^{(l)} = \frac{1}{\sqrt{|\mathcal{N}_u||\mathcal{N}_i|}} \left( \mathbf{W}_1^{(l)} \mathbf{e}_i^{(l-1)} + \mathbf{W}_2^{(l)} \left( \mathbf{e}_i^{(l-1)} \odot \mathbf{e}_u^{(l-1)} \right) \right)$$

$m_{u \leftarrow i}^{(l)}$：表示在第l层，从物品i传递给用户u的“消息” 。

 $\frac{1}{\sqrt{|\mathcal{N}_u||\mathcal{N}_i|}}$：这是一个归一化项，用来平衡不同度（连接数）的节点传来的信息，防止信息量爆炸 。

$W_1^{(l)} e_i^{(l-1)}$：这是最基础的信息传递，通过一个权重矩阵$W_1^{(l)}$对上一层的物品特征进行线性变换后传出 。

 $W_2^{(l)} (e_i^{(l-1)} \odot e_u^{(l-1)})$：这是NGCF的一个关键设计，它将用户和物品的特征进行**元素级乘积** ($\odot$)，以此来建模它们之间的**交互信息**，然后再通过$W_2^{(l)}$进行变换

**信息聚合公式 (Message Aggregation)**:

$$\mathbf{e}_u^{(l)} = \sigma \left( \mathbf{W}_1^{(l)} \mathbf{e}_u^{(l-1)} + \sum_{i \in \mathcal{N}_u} \mathbf{m}_{u \leftarrow i}^{(l)} \right)$$  
用户u在第l层的新特征，是由它自己的上一层特征和所有从邻居物品传来的“消息”聚合而成的 。
$\sigma(\cdot)$ 是非线性激活函数 。

**第三步：预测层**

- 将一个用户（或物品）在所有L层传播后得到的特征向量全部**拼接 (Concatenate)** 起来，形成最终的特征表示$e_u^*$ ​ 。
- 最后通过**内积**来预测用户对物品的偏好得分 。


### LightGCN

它移除了NGCF中所有**冗余的特征变换矩阵 (W) 和非线性激活函数 (σ)** 
传播公式：
$$\mathbf{e}_u^{(l+1)} = \sum_{i \in \mathcal{N}_u} \frac{1}{\sqrt{|\mathcal{N}_u|} \sqrt{|\mathcal{N}_i|}} \mathbf{e}_i^{(l)}, \quad
\mathbf{e}_i^{(l+1)} = \sum_{u \in \mathcal{N}_i} \frac{1}{\sqrt{|\mathcal{N}_i|} \sqrt{|\mathcal{N}_u|}} \mathbf{e}_u^{(l)}$$ 这个公式变得极其简洁。用户u在下一层的新特征，仅仅是其所有邻居物品i在当前层特征的**加权和** 。权重只与相连节点的度有关。

**LightGCN的预测层**：

- 它不再使用拼接，而是对不同传播层输出的嵌入向量进行**加权求和**，得到最终用于推荐的特征 $e_u^∗$​  。

## 图注意力网络建模

图注意力网络（GAT）则提出了一种更智能、更动态的思路：**并非所有邻居都同等重要，我们应该“有重点地”听取邻居的意见**。

注意力机制的计算过程
$$\alpha_{u,i} = \frac{exp(LeakyReLU(\boldsymbol{a}^T[W\boldsymbol{e}_u || W\boldsymbol{e}_i]))}{\sum_{j \in \mathcal{N}_u} exp(LeakyReLU(\boldsymbol{a}^T[W\boldsymbol{e}_u || W\boldsymbol{e}_j]))}$$

**特征变换**  ($W\boldsymbol{e}_u, W\boldsymbol{e}_i$ )：首先，用一个共享的权重矩阵$W$对中心节点（用户u）和邻居节点（物品i）的特征向量进行一次线性变换，可以理解为将它们的特征投影到一个新的空间，以便更好地进行比较。

**拼接 ($[\dots || \dots]$**)：将变换后的两个向量**拼接**在一起，形成一个更长的向量。

**计算注意力分数 ($\boldsymbol{a}^T[\dots]$**)：用一个可学习的注意力向量 $\boldsymbol{a}$ 和这个长向量做内积，得出一个**原始的注意力分数**。这个分数代表了节点u和节点i之间的关联强度。

**归一化 (Softmax)**：为了让分数更容易比较和使用，用一个Softmax函数对**中心节点u和它所有邻居**的原始注意力分数进行归一化。这样，每个邻居都会得到一个0到1之间的最终注意力权重 $\alpha_{u,i}$，并且所有邻居的权重加起来等于1。

只用一套注意力权重可能只能捕捉到一种关系模式。为了让模型学到更丰富的信息，GAT会**并行地运行多组独立的注意力机制**（即“多头”）。

通过多组注意力权重来分析不同交互模式

$$\mathbf{e}_u^{(l+1)} = \text{Aggregate}_{k=1}^K \left[ \sigma \left( \sum_{i \in \mathcal{N}_u} \alpha_{u,i}^k \mathbf{W}^k \mathbf{e}_i^{(l)} \right) \right]$$ 
最后，将所有“头”（所有顾问团）给出的结果进行聚合（比如拼接或平均），就能得到一个考虑了多种交互模式的、更强大、更全面的节点新特征。

总而言之，图注意力网络（GAT）通过引入**可学习的、动态的注意力权重**，实现了对邻居信息更加细粒度的聚合。它能够根据具体的数据和上下文，自适应地判断哪些邻居更重要，并结合**多头机制**从多个角度解耦和学习复杂的特征交互，从而有效提升了图表示学习的精度和表达能力。


# 基于扩散概率模型的推荐方法


- **前向过程（扩散）**：我们给这张图片逐步、反复地添加一点点“噪点”（随机噪声），直到它变成一片完全无法分辨的雪花（纯高斯噪声）。这个过程是固定的、不需要学习的。
- **反向过程（去噪）**：这是模型学习的关键。我们训练一个非常聪明的AI，让它看着这片“雪花”，学习如何**一步步地把噪点抹掉**，最终恢复出原始的高清图片。

推荐系统中，目标就是用户的**交互记录向量**（一个由0和1组成的长向量，1代表交互过，0代表没有）。扩散模型的目标就是学习这个从“纯噪声”恢复到“真实交互记录”的神奇过程。

## DiffRec模型

第一步：前向扩散过程 (Forward Process) - 加噪声

将用户的原始交互向量变为噪声

第二步：反向去噪过程 (Reverse Process) - 学习去噪

这是模型**学习**的核心。它需要从一个纯噪声 $x_T$ 开始，一步步地预测出前一个、更清晰的状态，直到恢复出 $x_0$ 

由神经网络驱动

模型的训练目标是让它预测的“上一步” $p_\theta(x_{t-1}|x_t)$，尽可能地接近于前向过程中真实的“上一步”分布 $q(x_{t-1}|x_t, x_0)$ 。这通常被简化为让神经网络去**预测在这一步中被添加的噪声**。只要能准确预测出噪声，就能从当前状态中减去噪声，从而得到上一步的状态。

证据下界
$$\log p(\mathbf{x}_0) \geq \underbrace{\mathbb{E}_{q(\mathbf{x}_1|\mathbf{x}_0)}[\log p_\theta(\mathbf{x}_0|\mathbf{x}_1)]}_{\text{任务1: 重构最终结果}} - \sum_{t=2}^{T} \underbrace{\mathbb{E}_{q(\mathbf{x}_t|\mathbf{x}_0)}[D_{KL}(q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0) \| p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t))]}_{\text{任务2: 学好每一步去噪}}$$ 
$\boldsymbol{x}_0$ 是原始的、清晰的用户交互记录。
$\boldsymbol{x}_1$ 是只加了**一步**噪声的、略微模糊的记录。
$p_\theta(\boldsymbol{x}_0|\boldsymbol{x}_1)$ 是模型（$p_\theta$）的能力：在看到略微模糊的$\boldsymbol{x}_1$后，它能**复原**出原始清晰记录 $\boldsymbol{x}_0$ 的概率有多大。
- **目标**: 我们希望这个概率越大越好。因此，模型的目标是**最大化**这一项。这确保了模型在接近终点时，有能力生成高质量、符合真实数据的最终结果 。

$D_{KL}(\dots || \dots)$: 这是**KL散度**，一种衡量两个概率分布有多么“接近”的数学工具。我们的目标是让这两个分布尽可能一致，也就是让KL散度的值**越小越好**。
$p_\theta(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t)$: 这是**模型的预测**。它代表模型在看到第t步的噪声状态 $\boldsymbol{x}_t$ 后，预测出的“上一步” ($\boldsymbol{x}_{t-1}$) 应该是什么样子的分布。这是**我们需要学习和优化的部分**。
$q(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t, \boldsymbol{x}_0)$: 这是“标准答案”。因为前向加噪声的过程是我们自己定义的，所以我们可以根据数学公式精确地计算出，在已知原始数据$\boldsymbol{x}_0$和当前噪声$\boldsymbol{x}_t$的情况下，前一步$\boldsymbol{x}_{t-1}$的真实分布应该是什么。这是一个**已知的、可计算的目标。
- **目标**: 通过最小化KL散度，模型被“逼着”去学习，让它的**反向去噪步骤 ($p_\theta$)** 完美地**模仿**真实的**反向去噪步骤 ($q$)** 。前面的负号 `-` 是因为，在整个最大化问题中，最小化KL散度就等同于最大化它的负值。

# Top-N推荐评价指标

评价好坏的三个常用标准。这三个指标分别是精确率 (Precision)、召回率 (Recall) 和归一化折损累计增益 (NDCG) 。

### 1. 精确率 (Precision@N)

- **核心思想**：衡量你的推荐有多“精准”，即你推荐的N个物品里，有多少是用户真正喜欢的。
### 2. 召回率 (Recall@N)

- **核心思想**：衡量你的推荐有多“全面”，即在用户所有真正喜欢的物品里，你成功推荐出来了多少。
### 归一化折损累计增益 (NDCG@N)

- **核心思想**：这是一个更高级、更科学的指标。它不仅关心你是否推荐对了，还关心你**推荐对的物品排在列表的什么位置**。把用户真正喜欢的物品排在第1位，比排在第10位要好得多。
- **计算过程**：
1. **DCG (Discounted Cumulative Gain, 折损累计增益)**：这是NDCG的基础。它会遍历推荐列表的前N个位置，如果该位置的物品是用户喜欢的，就加上一个分数；但这个分数会随着位置的靠后而“打折扣” (Discounted) 。具体来说，位置越靠后，除以的分母越大，分数就越小 。


2. **IDCG (Ideal DCG, 理想折损累计增益)**：计算一个**最理想情况**下的DCG值。也就是假设模型把用户所有喜欢的物品都完美地排在了推荐列表的最前面，这时候的DCG得分是多少 。
3. **NDCG**：最后，用真实的DCG除以理想的IDCG，即 `NDCG@N = DCG@N / IDCG@N` 。这样做可以把最终得分**归一化**到0和1之间，使得不同用户或不同推荐任务之间的结果可以公平比较。

# 融合用户社交与潜在群体偏好的集合式协同排序模型 

## 背景以及简述

### **成对偏好学习的“独立性假设”不合理**

PR的“独立性假设”认为，`A > B` 和 `C > D` 是两个不相干的线索。
**但实际上它们不是！** 

- `A > B` 的根本原因是 `A` 在“好东西”集合，`B` 在“坏东西”集合。
- `C > D` 的根本原因是 `C` 在“好东西”集合，`D` 在“坏东西”集合。

因为它们都源于同一个“好坏集合”的划分，所以它们是**高度相关的**。从这个划分中，我们还能推断出其他必然的结论，比如 `A > D`。`A > D` 这个“推论”的存在，证明了 `A > B` 和 `C > D` 之间存在着一个共同的、更深层次的逻辑联系，因此它们不可能是相互独立的。

**总结：** BPR的“独立性假设”之所以被破坏，是因为它把由**同一个根本原因**产生的多个“表象”（偏好对），错误地当成了多个**独立的、不相关的事件**来学习，从而忽略了这些“表象”之间内在的、必然的逻辑关联。


### **现有社交推荐模型的局限性** 

- **任务不匹配**：很多基于矩阵分解的社交推荐模型是为“评分预测”任务设计的，其优化目标与“Top-N推荐”的排序目标不一致 。
- **设计复杂**：一些为排序任务设计的模型，需要人为构建复杂的偏好规则和架构 。
- **信息源单一**：这些方法通常只关注用户**显式的社交关系**（如好友、关注），而忽略了那些没有直接社交联系、但兴趣可能非常相似的**潜在相关用户**的影响 。

### SGSR模型核心

- **采用“集合式”偏好建模**：
- 为了规避“独立性假设”问题，模型采用了一种更宽松的集合式思路 。它不再比较单个物品，而是假设**用户对自己交互过的“物品集合”的整体偏好，要大于对未交互过的“物品集合”的偏好** 。

- **融合“两种邻居”的协同信息**：
- 模型不仅利用了用户**显式的社交邻居**（好友）信息，还进一步挖掘并聚合了那些与用户兴趣相似但无直接社交联系的**潜在相关邻居**的信息，以此作为补充，获取更丰富的协同信号 。

- **保持“高效”**：
- 模型通过高效的采样策略和优化的算法，保持了较低的计算复杂度，确保了在实际应用中的高效运行 。

## 模型设计

用户和物品

用户的交互矩阵

用户的社交邻接矩阵

用户特征向量

物品特征向量

预测偏好分数

### 最终目标 

- 利用模型学习到的用户和物品的潜在特征向量 ($p_u$  和 $q_i$ )。
- **任务**: 为每一个用户 $u$ ，从他**从未交互过**的物品池 ($J_u^-$ ) 中，根据模型预测出的偏好分数 $\hat{r}$ 进行排序。
- **最终产出**: 识别并推荐排名最靠前的 **N** 个物品，从而实现**个性化推荐 (Top-N Recommendation)**。

# 集合式偏好学习建模 

## 核心

解决成对偏好学习方法相对严格的独立性假设问题
 从“单挑PK”到“团队作战”
- **成对（Pair-wise）方法的问题**：它把推荐问题看作无数场“**一对一的单挑**”。比如 `A > B`，`C > D`。它假设这些单挑比赛是相互独立的。
- **集合式（Set-wise）方法的新思路**：它认为用户的偏好更像是一场“**团队作战**”。它不再比较单个物品，而是提出了一个更宽松、更合理的假设：**用户对自己已经交互过的【物品集合】的整体偏好，要大于对未交互过的【物品集合】的偏好** 。

- **理想中的假设**：
    - 如论文中的**图3-2**所示，对于用户1，他交互过的物品是 `{A, C}`，未交互的是 `{B, D}` 。
    - 集合式方法的理想假设就是：`偏好({A, C}) > 偏好({B, D})` 。
- **现实中的实现**：
    - 直接比较两个集合的偏好在计算上非常复杂。因此，模型做了一个巧妙的简化。
    - 它将这个“团队战”分解为多场“**个人 vs 对方全队**”的比赛 。
    - 也就是说，`偏好({A, C}) > 偏好({B, D})` 被分解为两个子任务：
        1. **偏好(A) > 偏好({B, D})**
            
        2. **偏好(C) > 偏好({B, D})**

后验概率公式如下：
$$P(>_{u}|\Theta)=\prod_{i\in\mathcal{J}_{u}^{+}}P(i>_{u}\mathcal{M}_{u}|\Theta)=\prod_{i\in\mathcal{J}_{u}^{+}}\frac{\Phi(\hat{r}_{u,i})}{\Phi(\hat{r}_{u,i})+\sum_{j\in M_{u}}\Phi(\hat{r}_{u,j})}$$ 
$\prod_{i\in\mathcal{J}_{u}^{+}}$ ：它表示我们要对用户 `u` **所有交互过的物品 `i`**（正样本）都计算一次后面的概率，然后把这些概率全部乘起来 。

$P(i>_{u}\mathcal{M}_{u}|\Theta)$ 它代表模型预测“用户对单个正样本 `i` 的偏好，要大于对**整个负样本集合 $\mathcal{M}_{u}$ 的偏好”这件事的概率 。$\mathcal{M}_{u}$ 是从用户未交互的物品中采样出来的一个负样本集合 。

$\frac{\Phi(\hat{r}_{u,i})}{\Phi(\hat{r}_{u,i})+\sum_{j\in M_{u}}\Phi(\hat{r}_{u,j})}$ ：这是具体的计算方式，可以理解为一个 **Softmax** 函数
$\Phi(\hat{r}_{u,i})$ ：是正样本 `i` 的“能量得分”（$\Phi(x)$ 通常是 $e^x$，用来把预测分转换成正数）。
分母是正样本 `i` 的能量得分，**加上**负样本集合 $\mathcal{M}_{u}$  中**所有**物品的能量得分之和。

这个分数代表了，在${i} \cup \mathcal{M}_{u}$  这个临时的集合里，正样本 `i` 能够脱颖而出、被选为“Top-1”的概率是多少。

通过最大化上述集合式偏好结构的后验概率,即可学习到用户的偏好信息。

## 显式社交和潜在相关邻居信息聚合

### 显式社交邻居信息聚合 

在社交网络上和目标用户有直接连接的人，比如好友、关注者等 

- 模型会计算一个“社交特征向量” $f_u$，它是该用户所有社交邻居特征向量的**加权和**。
    
- **关键在于权重**：公式(3-3) $f_{u}=\sum_{v\in S_{u}}\frac{1}{\sqrt{|S_{v}|}}f_{v}$ 中，权重是 $1/\sqrt{|S_{v}|}$ 。
    
- **权重的逻辑**：这是一个非常智能的设计。如果你的一个朋友`v`是个“社交达人”，认识成千上万的人 ($|S_v|$ 很大)，那么他的品味可能比较宽泛，对你的影响力就应该**小一些** 。反之，如果一个朋友`v`的社交圈很小，那他的品味可能更具代表性，对你的影响力就应该**大一些** 。这避免了“意见领袖”过度影响推荐结果。

### 潜在相关邻居信息聚合

他们和目标用户**没有直接社交关系**，但是因为**交互过相同的物品**而被认为是“兴趣上的邻居”或“品味搭子”

遍历所有用户来计算相似度太慢了。模型采用了一种高效的**随机采样**策略：从所有和目标用户有过共同交互物品的人中，随机挑一小撮（比如`|G|`=3个）作为潜在相关邻居

- 和上面类似，模型会计算一个“潜在群体特征向量” $g_u$ ，它是这些潜在邻居特征向量的**加权和**。
    
- **关键在于权重**：公式(3-5) $g_{u}=\sum_{w\in G_{u}}\frac{1}{\sqrt{|J_{w}^{+}|}}p_{w}$ 中，权重是 $1/\sqrt{|J_{w}^{+}|}$ 。
    
- **权重的逻辑**：如果一个“品味搭子”`w`交互过的物品非常多 (`|J_w^+|`很大)，说明他兴趣广泛，其单一行为对你的参考价值就**小一些** 。反之，如果他只与少量物品有过交互，那这些交互行为就更能代表其精准的品味，对你的参考价值就**大一些** 。


## 偏好融合预测与目标函数设计 

- 通过一个简单的**线性加权**，将三个特征向量融合成一个最终的用户综合特征向量 $W_u$ 。
公式如下：
$$W_{u}=(1-\alpha-\beta)p_{u}+\alpha f_{u}+\beta g_{u}$$

最终融合偏好得分计算如下：
$$\hat{r}_{W_{u},i}=(1-\alpha-\beta)\hat{r}_{u,i}+\alpha\hat{r}_{S_{u},i}+\beta\hat{r}_{\mathcal{G}_{u},i}$$ 

模型有了这个最强的“综合偏好分” $\hat{r}_{W_{u,i}}$ ，就可以把它代入到之前3.2.2节的**集合式偏好学习框架**中，形成最终的优化目标。

 之前的假设是：`用户自己的偏好分(正样本) > 用户自己的偏好分(负样本集合)`。
 现在的假设是：`用户的综合偏好分(正样本) > 用户自己的偏好分(负样本集合)`。


$$\mathcal{L}_{SGSR}=\sum_{u=1}^{m}\sum_{l\in\mathcal{J}_{u}^{i}}-ln\frac{\Phi(\hat{r}_{W_{u}i})}{\Phi(\hat{r}_{W_{u}i})+\sum_{j\in M_{u}}\Phi(\hat{r}_{u,j})} + \text{正则化项}$$

它是在最大化一个概率——即用融合了邻居信息的、更强大的**综合分数 $\hat{r}_{W_{u}i}$** 去“战胜”一组由用户自己基本分数构成的负样本集合的概率。

**正则化项**: 和之前一样，这是为了防止模型过拟合，保持简洁性






# 基于扩散增强与跨视图协同对齐的社交推荐模型

## 社交网络中的噪声

在真实的社交网络中，大量用户与其社交好友的兴趣相似度其实**很低** 。你可能会因为同学、同事或家庭关系与某人成为好友，但你们的品味可能天差地别。这种**低同质性**的社交关系，对于推荐系统来说就是 **“噪声”** 。

**现有解决方案的局限性**

- **直接聚合很危险**：一些基于GNNs的方法直接在原始的、充满噪声的社交图上进行信息聚合，这很容易被噪声误导，从而学到错误的用户偏好 。
    
- **人工去噪策略不够智能**：一些研究工作尝试通过设置相似度门槛来筛掉不相关的用户，或者设计一些人工的自监督任务来辅助去噪 。但这些方法受限于固定的规则或任务设计，难以适应复杂多变的社交噪声 。

## 基于扩散增强与跨视图协同对齐的社交推荐模型(DCSR)

**目标**：为一个用户推荐他可能喜欢但还没接触过的物品。

**核心思路**：用户的喜好不仅体现在他**直接交互**过的物品上，也受其**社交圈**影响。但社交圈信息可能有噪声（不是所有朋友品味都一致）。我们需要**结合**这两种信息，并**净化**社交信息，使它们更好地协同工作。

**逻辑链条：**

1. **【起点：两种信息源】**

    - 我们有用户的 **交互记录**（喜欢/点击过什么物品）和 **社交网络**（和谁是好友）。

2. **【步骤1：初步“画像” - GNN编码 (4.2.1)】**

    - **目标**：为用户和物品先画一个初步的“画像”（向量表示）。
        
    - **怎么做**：
        - 用 **LightGCN** 处理“交互记录”，得到用户的 **交互画像** ($E_u^r$) 和物品的画像 ($E_i^r$)。
            - **交互画像**: 基于你喜欢的东西，描绘出的你。
        - 用 **GAT** 处理“社交网络”，得到用户的 **初始社交画像** ($E^s$)。
            - **初始社交画像**: 基于你的朋友们，描绘出的你（可能不太准）。
    - **结果**：现在每个用户有了两个不同的画像。
        
3. **【步骤2：“净化”社交画像 - 条件扩散 (4.2.2)】**
    
    - **目标**：修正“初始社交画像”，去除噪声，让它更接近用户真实的品味。
        
    - **怎么做**：
        - 使用 **扩散模型**。想象先把“初始社交画像”彻底打乱（加噪声），然后学习一步步复原它。
        - **关键创新**：复原过程不是瞎猜，而是要“**参考**”用户的“交互画像”（即他真正喜欢什么）。这个参考过程叫 **条件引导**。
        - **参考工具**：通过 **交叉注意力 (Cross-Attention)** 机制，让“被打乱的社交画像” (Query) 去“请教”用户的“交互历史” (Key, Value)，问：“根据我的朋友信息，结合你（用户实际喜好）来看，我应该是什么样子的？”
    - **结果**：得到一个 **净化后的社交画像** ($\tilde{E}^s$)，它既考虑了朋友影响，又被用户的真实喜好“校准”过。
        
4. **【步骤3：“语言统一” - 跨视图对齐 (4.2.3)】**
    
    - **目标**：“交互画像”和“净化后的社交画像”虽然都描述同一个用户，但可能是在用两种不同的“语言”（特征空间）。需要让它们“对齐”，方便后续融合。
        
    - **怎么做**：
        
        - 使用 **对比学习 (Contrastive Learning)**。
            
        - 先用两个 **投影头 (Projection Head)**（可以理解为“翻译器”）把两种画像翻译到同一个“公共语言空间”。
            
        - 然后告诉模型：对于**同一个用户**，他的两种翻译后的画像应该**互相靠近**；对于**不同用户**，他们的画像应该**互相远离**。
            
    - **结果**：得到 **对齐后的交互画像** ($z_u^r$) 和 **对齐后的社交画像** ($z_u^s$ )。
        
5. **【步骤4：“融合决策”与学习 (4.2.4)】**
    
    - **目标**：将两个对齐后的高质量画像融合成最终的用户画像，并进行推荐预测。
        
    - **怎么做**：
        
        - **融合**：使用 **自门控聚合 (Self-Gated Aggregation)**。模型会**自动学习**一个**门控值 (Gate)** $g_u$，决定对于这个用户，应该更相信“交互画像”多少，更相信“社交画像”多少，然后按比例混合。
            
        - **预测**：用最终融合的用户画像 ($\tilde{e}_u$) 和物品画像 ($E_i^r$) 做**内积**，得到预测分数。
            
        - **学习**：模型通过一个**总损失函数** ($\mathcal{L}_{total}$) 来学习。这个总损失包含了三个部分：①推荐做得好不好 (BPR Loss)，②社交画像净化得好不好 (Diffusion Loss)，③两种画像对齐得好不好 (Contrastive Loss)。







# 消融实验

缓解交互视图和社交视图之间的语义偏差、促进多源信息的一致性融合，是DCSR模型成功的关键因素。

# 用户活跃度分组的稀疏数据鲁棒性分析

这主要归功于DCSR采用的**条件引导扩散机制**和**跨视图对齐策略**。
这些机制有效提升了社交嵌入的质量，并在用户自身行为数据稀缺时，通过高质量的社交信息**补充**了用户的偏好信号。

 **自门控聚合模块能够智能地、自适应地调节来自不同视图的信息融合比例**，从而在一定程度上缓解了冷启动和数据稀疏问题，增强了模型对用户异质性的适应能力。

# 第四章小结

- **核心问题**: 本章研究主要围绕推荐系统中的**数据稀疏性**以及社交推荐中存在的**低同质性**（即社交噪声）问题展开 。
    
- **提出的模型**: 针对这些问题，提出了一种融合**扩散建模**与**多源表征对齐**的社交增强推荐模型 **DCSR** 。
    
- **关键技术**:
    
    - 首先使用图神经网络（结构感知的LightGCN和图注意力的GAT）分别编码用户-物品交互图和用户社交图中的高阶关系特征 。
        
    - 然后，引入创新的**条件扩散机制**，利用用户的**交互行为**作为先验知识（通过交叉注意力实现），引导用户**社交嵌入**的去噪重构与增强，从而实现更具偏好导向的特征建模 。
        
    - 接着，为了缓解交互视图和社交视图之间的**异构语义差异**，设计了**跨视图表征的对比对齐**策略 。
        
    - 最后，通过**自门控聚合模块**实现多源信息的自适应融合 。
        
- **主要成果**:
    
    - 在多个真实数据集上的实验表明，DCSR在**准确性**和**鲁棒性**方面均优于现有的模型方法 。
        
    - 特别是在**低活跃用户**（即数据稀疏）的场景下，DCSR依然表现优秀 。
        
    - 实验结果验证了DCSR模型在**多源建模**、**特征增强**与**视图对齐**等方面的有效性与实用价值 。


# 总结与展望

**第一项工作 (基于矩阵分解 - SGSR模型)**:

- **针对问题**: 传统基于矩阵分解的社交推荐方法存在任务适配性不足（多为评分预测设计）、结构设计复杂、仅依赖显式社交关系（协同建模片面）等问题 。
    
- **提出方案**: 融合用户社交关系与潜在群体偏好的**集合式协同排序模型 (SGSR)** 。
    
- **核心创新**:
    
    - 采用新颖的**集合式偏好学习**范式，避免了成对学习的独立性假设偏差和列表式排序的高计算开销 。
        
    - 联合**显式社交邻居**与基于交互挖掘的**潜在相关用户邻居**信息，实现协同信号的互补建模增强 。
        
    - 设计了**高效的潜在邻居识别**机制与参数优化流程，保持了良好的计算效率 。
        
- **实验证明**: 在四个真实数据集上显著优于现有基线方法，验证了融合显式社交邻居与潜在兴趣邻居的有效性 。

**第二项工作 (基于深度学习 - DCSR模型)**:

- **针对问题**: 现有深度社交推荐模型易受**低同质性社交关系**（噪声）干扰，且依赖的人工去噪策略泛化性差 。
    
- **提出方案**: 基于**扩散增强**与**跨视图协同对齐**的社交推荐模型 (DCSR) 。
    
- **核心创新**:
    
    - 通过图神经网络实现高阶关系编码 。
        
    - 利用**条件扩散机制**（以用户交互行为为条件，通过交叉注意力引导），对用户**社交嵌入**进行去噪增强，强化高质量社交信号 。
        
    - 通过**跨视图表征对比对齐**与**自门控聚合**模块，实现异构视图用户信息的语义融合与动态集成 。
        
- **实验证明**: 在推荐准确性与鲁棒性方面均显著优于现有方法，且在**低活跃用户**（数据稀疏）场景下依然保持稳定优越性能，展现出良好的泛化能力与实用潜力 。