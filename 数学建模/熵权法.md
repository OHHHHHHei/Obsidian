# 核心思想

一个指标的数据如果越离散（也就是说，各个评价对象在该指标上的数值差异越大），那么这个指标包含的信息量就越多，也就应该被赋予更高的权重。相反，如果所有对象在该指标上的数值都差不多，那这个指标就没提供什么有用的区分信息，权重就应该很低。

想象一下，你和朋友们正在评价几所大学，有两个评价指标：一个是“学费”，另一个是“校园风景评分”。
- **情况一：** 如果所有大学的学费都差不多，都在每年8000元左右。那么“学费”这个指标，对于你们区分哪所大学更好，帮助大不大呢？
- **情况二：** 如果“校园风景评分”这个指标，有的大学得了95分，有的60分，有的75分，分数差异很大。这个指标是不是就能提供更多有用的信息，帮助你们进行比较和选择？

熵权法的核心思想和这个例子一模一样。它认为，一个指标的数值如果差异越大（越离散），说明这个指标包含的“信息”就越多，在综合评价中就应该占据更重要的位置，也就是被赋予更高的权重。

在信息论中，我们用 **信息熵 (Information Entropy)** 这个概念来衡量一个指标数值的离散程度。
- **信息熵小**：表示一个指标的各个评价值都差不多，很整齐，没什么差异。就像情况一里的“学费”，它提供的信息量就少。
- **信息熵大**：表示一个指标的各个评价值差异很大，很混乱，很无序。就像情况二里的“校园风景评分”，它提供的信息量就多。
所以，熵权法的基本规则就是：**一个指标的信息熵越大，说明它能提供越多有用的区分信息，那么它在评价体系中的权重就应该越大。**

# 计算指标权重

我们可以把计算过程分成四个主要步骤：

1. **数据标准化**：消除不同指标量纲（单位）的影响。
2. **计算信息熵**：衡量每个指标的数据离散程度。
3. **计算信息熵冗余度**：把信息熵转化为更容易理解的差异度。
4. **计算权重**：根据差异度分配最终的权重。
## 数据标准化

比如，在评价大学时，“科研经费”可能是一个以“亿元”为单位的巨大数字，而“师生比”可能是一个0到1之间的小数。如果直接用这些原始数据计算，数值大的指标会不成比例地占据主导地位，这显然不公平。

在标准化之前，我们需要先判断指标的类型：
- **正向指标 (效益型指标)**：数值越大越好。比如“校园风景评分”、“毕业生就业率”。
- **负向指标 (成本型指标)**：数值越小越好。比如“学费”、“学生投诉率”。
这两种指标的标准化公式是不同的。假设我们有 $m$ 个评价对象和 $n$ 个指标，原始数据为 $x_{ij}$​（第 $i$ 个对象在第 $j$ 个指标下的值）。

**对于正向指标**，我们使用这个公式：
$$x'_{ij}​=\frac{x_{ij}​−min(x_j​)}{max(x_j​)−min(x_j​)}$$​

这里 $max(x_j​)$ 和 $min(x_j​)$ 分别是第 $j$ 个指标下的最大值和最小值。这个公式的作用是，原始值越接近最大值，标准化后的值就越接近$1$。

**对于负向指标**，我们使用这个公式：

$$x'_{ij}​=\frac{max(x_j​)−x_{ij}}{max(x_j​)−min(x_j​)}$$​​这个公式正好相反，原始值越小（越好），标准化后的值反而越接近1。
通过这两个公式处理后，所有指标的数值都被转换到了 `[0, 1]` 区间，并且数值越大代表越优。这样一来，所有指标就站在了同一起跑线上。

## 计算信息熵

这一步是熵权法的核心，它的目的是用一个具体的数值来衡量我们之前讨论的“指标数据的差异程度”。

这里的计算也分为两个小步骤：

**1. 计算第 $i$ 个对象在第 $j$ 个指标上的值所占的比重 ($p_{ij}$​)**

我们用上一步标准化后的数据 $x'_{ij}$​ 来计算。

$$p_{ij}=\frac{​x'_{ij}}{​\sum_{i=1}^mx'_{ij}​}$$
这个公式的意思是，计算某个数据点占其所在指标总和的比例。如果某个指标所有标准化后的值都一样，那么它们的比重 $p_{ij}$​ 也会完全相同。
**2. 计算第 j 个指标的信息熵 ($e_j$​)**

有了比重之后，就可以套用信息熵的经典公式了：
$$e_j = -k\sum_{i = 1}^m p_{ij} \ln(p_{ij})$$
其中，常数 $k$ 的计算公式是 $k=\frac{1}{\ln(m)}​$，$m$ 是评价对象的数量。设置这个 $k$ 的作用是为了让计算出的信息熵 $e_j$​ 的值落在 `[0, 1]` 区间内，方便后续的比较和计算。
（_注意：在计算中，如果某个比重 $p_{ij}​=0$，那么 $p_{ij} \ln(p_{ij})$ 的值在数学上没有意义，但在熵权法中我们直接定义此时 $p_{ij} \ln(p_{ij})$。_)
通过这个公式，我们就为每一个指标都算出了一个信息熵值 $e_j$​。

## 计算信息效用值（$d_j$）

我们定义一个“信息效用值”或者叫“差异度系数” dj​，计算公式是：

$$d_j​=1−e_j​$$

通过这一步转换：
- 如果信息熵 $e_j$​ 很小（说明数据差异大，指标有用），那么 $d_j​=1−e_j$​ 的值就会很 **大**。
- 如果信息熵 $e_j$​ 很大（说明数据差异小，指标没用），那么 $d_j​=1−e_j$​的值就会很 **小**。

这样一来，我们就得到了一个新的指标 $d_j$​，它的值越大，就代表原始数据差异越大，指标越重要。这就和我们的直觉完全一致了。

## 计算最终权重

我们已经为每个指标都计算出了一个信息效用值 $d_j$​，并且这个值越大，代表指标越重要。

最后一步就是把这些效用值进行“归一化”，得到的就是每个指标的最终权重。

公式如下：

$$w_j ​= \frac{dj}{\sum_{j=1}^n ​d_j​}$$​​

这个公式的意思是，第 $j$ 个指标的权重，等于它的信息效用值 $d_j$​ 除以 **所有** 指标的信息效用值之和。